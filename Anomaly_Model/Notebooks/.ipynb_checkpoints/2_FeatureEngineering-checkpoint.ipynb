{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc4382b-9e87-4e61-975d-b44f439db4cf",
   "metadata": {},
   "source": [
    "# Model Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75499f28-6656-4af4-9655-14685fdbe725",
   "metadata": {},
   "source": [
    "#### Import libraries section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T07:58:17.584793600Z",
     "start_time": "2024-06-05T07:58:17.549812600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Users/zemariatrindade/BTS/Financy_App/Scripts_and_Data/venv/lib/python3.11/site-packages\")\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5d996-76f2-4423-a178-2f0e4b1da14a",
   "metadata": {},
   "source": [
    "#### Importing env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6267aa5a7c1ddef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T07:58:10.247030200Z",
     "start_time": "2024-06-05T07:58:10.238951600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "dbname = os.getenv('db_name')\n",
    "user = os.getenv('db_username')\n",
    "password = os.getenv('db_password')\n",
    "host = os.getenv('db_host')\n",
    "port = os.getenv('db_port')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15690e79-5d72-4e32-9188-19c5809fd767",
   "metadata": {},
   "source": [
    "#### Importing anomalies found with reseach to annotate our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452485c-b0a1-45c1-9d73-15a88ad92684",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_df = pd.read_csv(\"Anomalies_tracker.csv\")\n",
    "anomalies_df['cik_str'] = anomalies_df['cik_str'].astype(str).str.zfill(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d328fa12-a686-4216-a6e7-2732e2404f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5042ab-ef3e-408a-95bb-da789c6ab803",
   "metadata": {},
   "source": [
    "##### Making sure we don't have the same anomaly repeated\n",
    "In the Anomalies_tracker, we had different tickers for the same cik number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c56c3-ec11-409b-bb37-3bd52930f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_df = anomalies_df.drop_duplicates(subset=[\"cik_str\",\"Scandal Year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2210636-6717-474f-9abb-6452374caf7e",
   "metadata": {},
   "source": [
    "##### filtering for the years and forms format where we have data to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5cbe55-5846-45df-8317-8b901c91742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_cases = anomalies_df[(anomalies_df[\"XBRL format\"]==\"Yes\") & (anomalies_df[\"10-Q/ 10-K available\"]==\"Yes\")][[\"cik_str\",\"Scandal Year\",\"Anomaly Ticker\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51bd97b-5ed1-460c-a3f1-6cf49eb5278a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of cases:\", len(anomaly_cases))\n",
    "print(\"Number of tickers:\", len(anomaly_cases[\"Anomaly Ticker\"].unique()))\n",
    "\n",
    "anomaly_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29f33a-3d6a-4333-9191-8acb1a1d6f2e",
   "metadata": {},
   "source": [
    "We have a total of 53 anomaly cases. We assume the company was anomalous the entire year. Given that we have more than 1 type of report per year, we will end up with more total anomalous entries.\n",
    "\n",
    "These 53 anomaly cases represent 40 companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256bd7da-7e5f-4942-89b2-dbf41c2103e5",
   "metadata": {},
   "source": [
    "#### Querying the aws RDS database\n",
    "for the tickers we have found at least 1 anomaly record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e219bb-51bb-4744-8211-dc8f8ce6c173",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_tickers = tuple(anomaly_cases[\"Anomaly Ticker\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659bcabbe5a45ae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T07:59:08.649825500Z",
     "start_time": "2024-06-05T07:58:19.167075300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "conn = psycopg2.connect(dbname=dbname,\n",
    "                        user=user,\n",
    "                        password=password,\n",
    "                        host=host,\n",
    "                        port=port)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT * \n",
    "    FROM edgar_selected_tickers_table\n",
    "    WHERE ticker in {tuple_tickers};\n",
    "\"\"\"\n",
    "cursor.execute(query)\n",
    "results = cursor.fetchall()\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b715511f42dad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:01:12.643700300Z",
     "start_time": "2024-06-05T08:01:12.461030200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_names = ['end_date', 'ticker', 'reporting_frame', 'form', 'account', 'unit', 'value']\n",
    "query_df = pd.DataFrame(results, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d4904-2649-4b3a-98ae-b657614247ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df.ticker.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea2d8c-84d9-45fd-82ab-5d0409626557",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df[\"year\"] = query_df[\"end_date\"].apply(lambda x: int(x.strftime(\"%Y\")))\n",
    "query_df = query_df.iloc[:,[0,7,1,2,3,4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb31dd3-2256-41ca-b042-90d3f2dfa052",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5453b-cf15-41aa-b594-f82a52ab570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8996d1-f78c-4884-aab9-00e9e5d152f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df.account.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62741d4f-7214-44bc-a1c6-98a01b09a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df.form.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e4523d-84ef-4d68-9fd1-706c95af03ba",
   "metadata": {},
   "source": [
    "## Hypothesis Brach: Supervised model\n",
    "Let's use the anomaly years (anomaly_cases) to match with the reports of those same years present in EDGAR.\n",
    "And we will use the matches as binary classification cols.\n",
    "\n",
    "1. we run a pivot table on top of the query to get the accounts as columns\n",
    "2. we create a label column called \"anomaly\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4226946a-6e95-44a8-8600-5d4a9ad6cdc5",
   "metadata": {},
   "source": [
    "1. getting the accounts as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8131d8ec772a66f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:03:59.316520800Z",
     "start_time": "2024-06-05T08:03:56.190411400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivoted_df = query_df.pivot_table(index=['end_date','year', 'ticker', 'reporting_frame', 'form', 'unit'], \n",
    "                            columns='account',\n",
    "                            values='value',\n",
    "                            aggfunc='sum',\n",
    "                            fill_value=0)\n",
    "# Fill any NaN values that might be created in the process.\\We have to justify why 0 is a valid value.\n",
    "pivoted_df = pivoted_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d946f6-d395-4b15-a5ca-6ba0116529cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023cd2aa-3d6d-42b5-8f5d-7d360f3c9f54",
   "metadata": {},
   "source": [
    "2. creating the label column \"anomaly\"\n",
    "\n",
    "Assumptions:\n",
    "- we will assign the value \"1\" to every date in the respective anomaly year\n",
    "- we will use all type forms: 10-K, 10-Q, 8-K\n",
    "- what types of anomalies are we considering? should we include all of them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebea8043-19c6-4be2-ba9c-0eafefc8b95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pivoted_df.merge(anomaly_cases, how=\"left\",left_on=[\"ticker\",\"year\"], right_on=[\"Anomaly Ticker\",\"Scandal Year\"], indicator=True)\n",
    "merged_df.drop(labels=[\"Scandal Year\",\"Anomaly Ticker\",\"cik_str\"], axis=1, inplace=True)\n",
    "merged_df['anomaly'] = (merged_df['_merge'] == 'both').astype(int)\n",
    "merged_df.drop(labels=[\"_merge\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025d883-b211-40b2-a813-737d1974145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.anomaly.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a095d19-ce18-450b-8d00-d65771aa5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b67635-8092-4105-bdd7-c772ec763cd0",
   "metadata": {},
   "source": [
    "#### Discovery: 8.7% of the values are anomalies\n",
    "assuming we are using all the type forms and all forms are anomalous in a given anomalous year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becbb1a2-88ea-439f-86fa-c61f57101b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5708fd7-8947-4350-a141-c48d0d082945",
   "metadata": {},
   "source": [
    "### to-dos:\n",
    "1. use karens data with the anomalies updated: same tickers, but different anomaly years >> only for netflix and deleted \n",
    "2. keep working on feature engineering\n",
    "2. try models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305ad6e8-1437-40df-ae12-e741bcee056c",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "1. Handling Missing values - let's treat the null values as meaningful zeros.\n",
    "2. Scaling and Normalization\n",
    "3. Dimensionality Reduction\n",
    "   1. PCA\n",
    "   2. Feature selection with autoencoding\n",
    "4. Encoding Categorical Variables\n",
    "5. Generating Interaction Features:\n",
    "6. Handling Imbalanced Data\n",
    "7. Time-Based Features:\n",
    "If the data is time-series in nature, consider generating lag features, rolling averages, or other time-based features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1fc409-2d3a-438a-83c4-cf1fb91516c3",
   "metadata": {},
   "source": [
    "### 1. Scaling\n",
    "For the task of finding anomalies in a diverse dataset with varying scales and potential outliers, Robust Scaling is highly recommended due to its robustness to outliers. Since financial data often includes extreme values and outliers, Robust Scaling will ensure that these outliers do not disproportionately affect the scaling process, leading to better model performance and more reliable anomaly detection.\n",
    "\n",
    "However, it can be beneficial to **experiment with both Standardization and Robust Scaling**, then evaluate model performance using cross-validation to determine the best approach for our specific dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5fe18a-e8f3-4d21-8d85-85296e37cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = list(merged_df.select_dtypes(include=['int', 'float']).columns)#\n",
    "numerical_cols.remove(\"year\")\n",
    "numerical_cols.remove(\"anomaly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554b02e3-09b5-48d8-9193-b9bef903b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.unit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96ed86-e284-4ede-afeb-38512168f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.reporting_frame.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb78778-bf1e-40c8-9eca-d76cc34404a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df.reporting_frame==\"us-gaap\"].unit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f7189c-52f1-4001-9b87-6b146ce922ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[merged_df.reporting_frame==\"dei\"].unit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72731d0c-8e31-4007-a8e6-f50c565398f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df[query_df.unit==\"pure\"].account.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65b888d-41db-447f-ae76-e66513cddc2b",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "1. Logistic regression\n",
    "2. Tree-Based Models: Random forest and Gradient Boosting Machines (GBM): (e.g., XGBoost, LightGBM, CatBoost)\n",
    "3. Support Vector Machines (SVM)\n",
    "4. Neural Networks: MLPs and CNN, LSTMs\n",
    "5. Ensemble Methods\n",
    "6. Anomaly Detection Algorithms: Given the nature of anomalies, consider specialized anomaly detection techniques like Isolation Forest, One-Class SVM, or Autoencoders for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86db1e0a-7a90-4e59-bc6f-4c8ee6e4d564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d2c899-bfd2-4488-89e9-ba0d55808ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df43e41-ff6b-47e0-ad81-9c905aecd572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033223d28b679a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:07:49.639529600Z",
     "start_time": "2024-06-05T08:07:49.623298200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=pivoted_df.iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4106034fce85b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:14:27.955074700Z",
     "start_time": "2024-06-05T08:14:27.463986300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled=scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c00a3948ce747",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:14:28.415065200Z",
     "start_time": "2024-06-05T08:14:27.965068900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train Model\n",
    "model = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    max_samples=200,\n",
    "    contamination=0.01,\n",
    "    max_features=1.0,\n",
    "    bootstrap=False,\n",
    "    n_jobs=-1, # Using available processors from computer\n",
    "    random_state=42,\n",
    ")\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f0cdf18b45a64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:14:30.454574400Z",
     "start_time": "2024-06-05T08:14:30.204678600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2737bc1f06f6a36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:16:14.112133100Z",
     "start_time": "2024-06-05T08:16:14.097397500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivoted_df.iloc[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b06929b0f5188a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:17:17.592150800Z",
     "start_time": "2024-06-05T08:17:17.503607100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X)\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "final_df = pd.concat([pivoted_df.iloc[:,:5],X_df , y_pred_df], axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc45fd33145ddb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:22:14.175697700Z",
     "start_time": "2024-06-05T08:22:14.160915200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anomalies_detected=final_df[final_df[0] == -1]\n",
    "#Creating a df with the list of anomalies\n",
    "anomalies_df = pd.DataFrame(companies_with_anomalies, columns=['id', 'ticker', 'year', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b961ca1151c6369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T08:24:31.921480500Z",
     "start_time": "2024-06-05T08:24:31.911004400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "match_anomalies = pd.merge(anomalies_detected, anomalies_df, on='ticker', how='inner')\n",
    "match_anomalies[['ticker', 'year', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a2616ef6e6c18",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
