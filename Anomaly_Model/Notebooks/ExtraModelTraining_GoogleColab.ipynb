{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EnWbDv2sQZ1"
   },
   "source": [
    "# Extra Model Training\n",
    "## **Disclaimer**: This notebook is to be run in Google Colab with GPU.\n",
    "\n",
    "In order to run this notebook you will need to have the file processed_consolidated_data.csv and processed_filtered_data.csv in your current directory.\n",
    "\n",
    "The goal of this notebook is to run the models trainings that were note possible to do in the Modelling notebook, because there wasn't enough computer power.\n",
    "\n",
    "This notebook should output a csv file with the evaluation metrics that will be then loaded by the Modelling notebook to compare results.\n",
    "\n",
    "We do RandomSearchCV on both datasets and on the models: RandomForestClassifier and Gradient Boosting.\n",
    "In addition to this, we will also run the AutoEncoder model for both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPWJ3kvNsOeU"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wMmGOiTjn2-j"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, recall_score,\n",
    "                      confusion_matrix, classification_report)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gxJCBde7BiQA"
   },
   "outputs": [],
   "source": [
    "results_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZycv4K4tHwk"
   },
   "source": [
    "### 1st dataset consolidated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eLTU3yLCs97q"
   },
   "outputs": [],
   "source": [
    "# Step: Load your dataset\n",
    "# Assume X and y are loaded properly\n",
    "filtered_df = pd.read_csv(\"processed_consolidated_data.csv\")\n",
    "X = filtered_df.drop(\"anomaly\", axis=1)\n",
    "y = filtered_df[\"anomaly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ncfQOAA6s9-P"
   },
   "outputs": [],
   "source": [
    "# Step: Prepare the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hm5FEgLn4Pi_"
   },
   "outputs": [],
   "source": [
    "# Applying SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_con_resampled, y_train_con_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CENP_huL4DE8"
   },
   "source": [
    "#### RandomForest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SWeMJga35WC",
    "outputId": "216e1fa5-04df-4b75-f656-a3cee7aba7d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid = os.fork()\n",
      "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier:\n",
      "Accuracy: 0.9136690647482014\n",
      "\n",
      "Confusion Matrix:\n",
      "[[978  39]\n",
      " [ 57  38]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      1017\n",
      "           1       0.49      0.40      0.44        95\n",
      "\n",
      "    accuracy                           0.91      1112\n",
      "   macro avg       0.72      0.68      0.70      1112\n",
      "weighted avg       0.91      0.91      0.91      1112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  # Number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider at every split\n",
    "    'max_depth': [None, 10, 20],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False]  # Method for sampling data points (with or without replacement)\n",
    "}\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Randomized Search CV\n",
    "random_search_rf_1 = RandomizedSearchCV(estimator=rf_classifier,\n",
    "                                   param_distributions=param_grid,\n",
    "                                   scoring=\"recall\",\n",
    "                                   cv=5,  # Adjust cross-validation as needed\n",
    "                                   n_iter=10,  # Number of random combinations to try\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1)  # Use all available CPU cores\n",
    "\n",
    "# Fit Randomized Search\n",
    "random_search_rf_1.fit(X_train_con_resampled, y_train_con_resampled)\n",
    "\n",
    "# Predict anomalies on the test set\n",
    "y_pred_rf = random_search_rf_1.predict(X_test)\n",
    "\n",
    "results_dict = {\"Model\":\"RandomForest with RandomizedSearchCV\",\n",
    "                \"Dataset\":\"Consolidated\",\n",
    "                \"Accuracy\":accuracy_score(y_test, y_pred_rf),\n",
    "                \"Recall\":recall_score(y_test, y_pred_rf)}\n",
    "\n",
    "results_list.append(results_dict)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nRandom Forest Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf)}\\n\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_rf)}\\n\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_rf, zero_division=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_abq2kN74JL_"
   },
   "source": [
    "#### Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "as0n9Vvh35Zn",
    "outputId": "53d709f8-b647-4e9d-a84c-64599e8e4859"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Gradient Boosting Model:\n",
      "Accuracy: 0.9064748201438849\n",
      "\n",
      "Confusion Matrix:\n",
      "[[971  46]\n",
      " [ 58  37]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95      1017\n",
      "           1       0.45      0.39      0.42        95\n",
      "\n",
      "    accuracy                           0.91      1112\n",
      "   macro avg       0.69      0.67      0.68      1112\n",
      "weighted avg       0.90      0.91      0.90      1112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid for Gradient Boosting\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  # Number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider at every split\n",
    "    'max_depth': [None, 10, 20],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Randomized Search CV\n",
    "random_search_gb_1 = RandomizedSearchCV(estimator=gb_classifier,\n",
    "                                   param_distributions=param_grid,\n",
    "                                   scoring=\"recall\",\n",
    "                                   cv=5,  # Adjust cross-validation as needed\n",
    "                                   n_iter=10,  # Number of random combinations to try\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1)  # Use all available CPU cores\n",
    "\n",
    "# Fit Randomized Search\n",
    "random_search_gb_1.fit(X_train_con_resampled, y_train_con_resampled)\n",
    "\n",
    "# Predict anomalies on the test set\n",
    "y_pred_gb = random_search_gb_1.predict(X_test)\n",
    "\n",
    "results_dict = {\"Model\":\"Gradient Boosting with RandomizedSearchCV\",\n",
    "                \"Dataset\":\"Consolidated\",\n",
    "                \"Accuracy\":accuracy_score(y_test, y_pred_gb),\n",
    "                \"Recall\":recall_score(y_test, y_pred_gb)}\n",
    "\n",
    "results_list.append(results_dict)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\Gradient Boosting Model:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_gb)}\\n\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_gb)}\\n\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_gb, zero_division=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MRK9TvG38ZU"
   },
   "source": [
    "#### Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KHeivs4Js-D9"
   },
   "outputs": [],
   "source": [
    "# Step 4: Build the Autoencoder\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 14\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "encoder = Dense(int(encoding_dim / 4), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 4), activation='relu')(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation='relu')(decoder)\n",
    "decoder = Dense(input_dim, activation='sigmoid')(decoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KqUlS5aHtQWZ",
    "outputId": "a9a39e67-d776-4628-e1ff-65bcda7e1d40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "127/127 [==============================] - 2s 4ms/step - loss: 353.4977 - val_loss: 371.7548\n",
      "Epoch 2/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 351.2465 - val_loss: 370.4230\n",
      "Epoch 3/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.7319 - val_loss: 370.2450\n",
      "Epoch 4/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 350.6408 - val_loss: 370.2101\n",
      "Epoch 5/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 350.6191 - val_loss: 370.1984\n",
      "Epoch 6/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.6080 - val_loss: 370.1848\n",
      "Epoch 7/50\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 350.5961 - val_loss: 370.1695\n",
      "Epoch 8/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 350.5586 - val_loss: 370.0820\n",
      "Epoch 9/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 350.5167 - val_loss: 370.0713\n",
      "Epoch 10/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 350.4806 - val_loss: 370.0498\n",
      "Epoch 11/50\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 350.4519 - val_loss: 370.0175\n",
      "Epoch 12/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.4287 - val_loss: 369.9967\n",
      "Epoch 13/50\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 350.4248 - val_loss: 369.9897\n",
      "Epoch 14/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.4164 - val_loss: 369.9835\n",
      "Epoch 15/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.4100 - val_loss: 369.9799\n",
      "Epoch 16/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.4088 - val_loss: 369.9765\n",
      "Epoch 17/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.4064 - val_loss: 369.9746\n",
      "Epoch 18/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.4049 - val_loss: 369.9742\n",
      "Epoch 19/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.3976 - val_loss: 369.9714\n",
      "Epoch 20/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.3955 - val_loss: 369.9691\n",
      "Epoch 21/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.3952 - val_loss: 369.9669\n",
      "Epoch 22/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.3903 - val_loss: 369.9599\n",
      "Epoch 23/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.3586 - val_loss: 369.8654\n",
      "Epoch 24/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.2984 - val_loss: 369.8589\n",
      "Epoch 25/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.2961 - val_loss: 369.8673\n",
      "Epoch 26/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.2950 - val_loss: 369.8557\n",
      "Epoch 27/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.2922 - val_loss: 369.8570\n",
      "Epoch 28/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.2895 - val_loss: 369.8582\n",
      "Epoch 29/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.2870 - val_loss: 369.8500\n",
      "Epoch 30/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.2830 - val_loss: 369.8516\n",
      "Epoch 31/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.2824 - val_loss: 369.8503\n",
      "Epoch 32/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.2830 - val_loss: 369.8534\n",
      "Epoch 33/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.2803 - val_loss: 369.8468\n",
      "Epoch 34/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.2771 - val_loss: 369.8404\n",
      "Epoch 35/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.2781 - val_loss: 369.8383\n",
      "Epoch 36/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.2763 - val_loss: 369.8393\n",
      "Epoch 37/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.2728 - val_loss: 369.8389\n",
      "Epoch 38/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.2691 - val_loss: 369.8330\n",
      "Epoch 39/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.2686 - val_loss: 369.8324\n",
      "Epoch 40/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.2671 - val_loss: 369.8320\n",
      "Epoch 41/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.2671 - val_loss: 369.8337\n",
      "Epoch 42/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 350.2628 - val_loss: 369.8311\n",
      "Epoch 43/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.2669 - val_loss: 369.8333\n",
      "Epoch 44/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 350.2668 - val_loss: 369.8390\n",
      "Epoch 45/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 350.2610 - val_loss: 369.8285\n",
      "Epoch 46/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 350.2607 - val_loss: 369.8417\n",
      "Epoch 47/50\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 350.2595 - val_loss: 369.8354\n",
      "Epoch 48/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 350.2604 - val_loss: 369.8295\n",
      "Epoch 49/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 350.2567 - val_loss: 369.8259\n",
      "Epoch 50/50\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 350.2574 - val_loss: 369.8398\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train the Autoencoder\n",
    "X_train_normal = X_train[y_train == 0]\n",
    "\n",
    "history = autoencoder.fit(X_train_normal, X_train_normal,\n",
    "                          epochs=50,\n",
    "                          batch_size=32,\n",
    "                          validation_data=(X_test[y_test == 0], X_test[y_test == 0]),\n",
    "                          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQKrgzUktQZM",
    "outputId": "ba3cb23b-c245-4426-bb94-2f994df5f231"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Set a Threshold for Reconstruction Error\n",
    "reconstructions = autoencoder.predict(X_train_normal)\n",
    "reconstruction_errors = np.mean(np.square(reconstructions - X_train_normal), axis=1)\n",
    "threshold = np.percentile(reconstruction_errors, 63)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHxLMSWRtQb6",
    "outputId": "80bee59a-9690-490e-d16c-51be68e1cdd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Detect Anomalies on Test Data\n",
    "test_reconstructions = autoencoder.predict(X_test)\n",
    "test_reconstruction_errors = np.mean(np.square(test_reconstructions - X_test), axis=1)\n",
    "y_pred = (test_reconstruction_errors > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kpQjzjqXtQes",
    "outputId": "f35ccf9d-b929-4148-ac65-c58f1298a95d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5881294964028777\n",
      "Confusion Matrix:\n",
      " [[610 407]\n",
      " [ 51  44]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.60      0.73      1017\n",
      "           1       0.10      0.46      0.16        95\n",
      "\n",
      "    accuracy                           0.59      1112\n",
      "   macro avg       0.51      0.53      0.44      1112\n",
      "weighted avg       0.85      0.59      0.68      1112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Evaluate the Model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ROviGgl0Epzx"
   },
   "outputs": [],
   "source": [
    "results_dict = {\"Model\":\"AutoEncoder\",\n",
    "                \"Dataset\":\"Consolidated\",\n",
    "                \"Accuracy\":accuracy_score(y_test, y_pred),\n",
    "                \"Recall\":recall_score(y_test, y_pred)}\n",
    "\n",
    "results_list.append(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "san0mUwFtouK"
   },
   "source": [
    "### 2nd dataset filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "EfDRFjqipC_p"
   },
   "outputs": [],
   "source": [
    "# Step: Load your dataset\n",
    "# Assume X and y are loaded properly\n",
    "filtered_df = pd.read_csv(\"processed_filtered_data.csv\")\n",
    "X = filtered_df.drop(\"anomaly\", axis=1)\n",
    "y = filtered_df[\"anomaly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zdDYLwaQpF38"
   },
   "outputs": [],
   "source": [
    "# Step: Prepare the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "WimYfjG64lKx"
   },
   "outputs": [],
   "source": [
    "# Applying SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_filter_resampled, y_train_filter_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvLxtvxa4ugG"
   },
   "source": [
    "#### Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bamfFR9i8XJ6",
    "outputId": "da911e20-8f2a-4d48-f065-10ea5509bb62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier:\n",
      "Accuracy: 0.8803956834532374\n",
      "\n",
      "Confusion Matrix:\n",
      "[[940  77]\n",
      " [ 56  39]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      1017\n",
      "           1       0.34      0.41      0.37        95\n",
      "\n",
      "    accuracy                           0.88      1112\n",
      "   macro avg       0.64      0.67      0.65      1112\n",
      "weighted avg       0.89      0.88      0.89      1112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  # Number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider at every split\n",
    "    'max_depth': [None, 10, 20],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False]  # Method for sampling data points (with or without replacement)\n",
    "}\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Randomized Search CV\n",
    "random_search_rf_2 = RandomizedSearchCV(estimator=rf_classifier,\n",
    "                                   param_distributions=param_grid,\n",
    "                                   scoring=\"recall\",\n",
    "                                   cv=5,  # Adjust cross-validation as needed\n",
    "                                   n_iter=50,  # Number of random combinations to try\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1)  # Use all available CPU cores\n",
    "\n",
    "# Fit Randomized Search\n",
    "random_search_rf_2.fit(X_train_filter_resampled, y_train_filter_resampled)\n",
    "\n",
    "# Predict anomalies on the test set\n",
    "y_pred_rf = random_search_rf_2.predict(X_test)\n",
    "\n",
    "results_dict = {\"Model\":\"RandomForest with RandomizedSearchCV\",\n",
    "                \"Dataset\":\"Filtered\",\n",
    "                \"Accuracy\":accuracy_score(y_test, y_pred_rf),\n",
    "                \"Recall\":recall_score(y_test, y_pred_rf)}\n",
    "\n",
    "results_list.append(results_dict)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nRandom Forest Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf)}\\n\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_rf)}\\n\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_rf, zero_division=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuNCeoQD4uqy"
   },
   "source": [
    "#### Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kK6U8EK046oq",
    "outputId": "1e8e4af9-654a-44e5-b5c5-9e2f5436bd03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classifier:\n",
      "Accuracy: 0.8794964028776978\n",
      "\n",
      "Confusion Matrix:\n",
      "[[942  75]\n",
      " [ 59  36]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93      1017\n",
      "           1       0.32      0.38      0.35        95\n",
      "\n",
      "    accuracy                           0.88      1112\n",
      "   macro avg       0.63      0.65      0.64      1112\n",
      "weighted avg       0.89      0.88      0.88      1112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid for Gradient Boosting\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],  # Number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider at every split\n",
    "    'max_depth': [None, 10, 20],  # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Initialize Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Randomized Search CV\n",
    "random_search_gb_2 = RandomizedSearchCV(estimator=gb_classifier,\n",
    "                                   param_distributions=param_grid,\n",
    "                                   scoring=\"recall\",\n",
    "                                   cv=5,  # Adjust cross-validation as needed\n",
    "                                   n_iter=50,  # Number of random combinations to try\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1)  # Use all available CPU cores\n",
    "\n",
    "# Fit Randomized Search\n",
    "random_search_gb_2.fit(X_train_filter_resampled, y_train_filter_resampled)\n",
    "\n",
    "# Predict anomalies on the test set\n",
    "y_pred_gb = random_search_gb_2.predict(X_test)\n",
    "\n",
    "results_dict = {\"Model\":\"Gradient Boosting with RandomizedSearchCV\",\n",
    "                \"Dataset\":\"Filtered\",\n",
    "                \"Accuracy\":accuracy_score(y_test, y_pred_gb),\n",
    "                \"Recall\":recall_score(y_test, y_pred_gb)}\n",
    "\n",
    "results_list.append(results_dict)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nGradient Boosting Classifier:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_gb)}\\n\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_gb)}\\n\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_gb, zero_division=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sdZBu8K4u7V"
   },
   "source": [
    "#### AutoEncoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yk4h2bzCpGC8"
   },
   "outputs": [],
   "source": [
    "# Step 4: Build the Autoencoder\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 14\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "encoder = Dense(int(encoding_dim / 4), activation=\"relu\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 4), activation='relu')(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation='relu')(decoder)\n",
    "decoder = Dense(input_dim, activation='sigmoid')(decoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOgjaMOIpSiw",
    "outputId": "34d44567-0a74-4e00-e164-f93c85bd6905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "127/127 [==============================] - 2s 4ms/step - loss: 1.1412 - val_loss: 0.9383\n",
      "Epoch 2/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.7549 - val_loss: 0.6493\n",
      "Epoch 3/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.6443 - val_loss: 0.6377\n",
      "Epoch 4/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.6372 - val_loss: 0.6325\n",
      "Epoch 5/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.6334 - val_loss: 0.6299\n",
      "Epoch 6/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.6312 - val_loss: 0.6282\n",
      "Epoch 7/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6300 - val_loss: 0.6273\n",
      "Epoch 8/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.6291 - val_loss: 0.6265\n",
      "Epoch 9/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.6284 - val_loss: 0.6257\n",
      "Epoch 10/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6276 - val_loss: 0.6248\n",
      "Epoch 11/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.6267 - val_loss: 0.6239\n",
      "Epoch 12/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.6258 - val_loss: 0.6228\n",
      "Epoch 13/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6249 - val_loss: 0.6216\n",
      "Epoch 14/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.6237 - val_loss: 0.6203\n",
      "Epoch 15/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.6225 - val_loss: 0.6190\n",
      "Epoch 16/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6211 - val_loss: 0.6173\n",
      "Epoch 17/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6193 - val_loss: 0.6158\n",
      "Epoch 18/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6176 - val_loss: 0.6138\n",
      "Epoch 19/50\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.6157 - val_loss: 0.6121\n",
      "Epoch 20/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6138 - val_loss: 0.6103\n",
      "Epoch 21/50\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 0.6117 - val_loss: 0.6075\n",
      "Epoch 22/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6086 - val_loss: 0.6037\n",
      "Epoch 23/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6042 - val_loss: 0.5994\n",
      "Epoch 24/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6008 - val_loss: 0.5967\n",
      "Epoch 25/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5988 - val_loss: 0.5955\n",
      "Epoch 26/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5974 - val_loss: 0.5938\n",
      "Epoch 27/50\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.5961 - val_loss: 0.5927\n",
      "Epoch 28/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5949 - val_loss: 0.5912\n",
      "Epoch 29/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5935 - val_loss: 0.5894\n",
      "Epoch 30/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5910 - val_loss: 0.5867\n",
      "Epoch 31/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5883 - val_loss: 0.5842\n",
      "Epoch 32/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5855 - val_loss: 0.5819\n",
      "Epoch 33/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5833 - val_loss: 0.5804\n",
      "Epoch 34/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5820 - val_loss: 0.5789\n",
      "Epoch 35/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5809 - val_loss: 0.5775\n",
      "Epoch 36/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5796 - val_loss: 0.5761\n",
      "Epoch 37/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5785 - val_loss: 0.5750\n",
      "Epoch 38/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5775 - val_loss: 0.5746\n",
      "Epoch 39/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5764 - val_loss: 0.5734\n",
      "Epoch 40/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5752 - val_loss: 0.5721\n",
      "Epoch 41/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5737 - val_loss: 0.5692\n",
      "Epoch 42/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5720 - val_loss: 0.5681\n",
      "Epoch 43/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5708 - val_loss: 0.5662\n",
      "Epoch 44/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5693 - val_loss: 0.5658\n",
      "Epoch 45/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5685 - val_loss: 0.5654\n",
      "Epoch 46/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5678 - val_loss: 0.5649\n",
      "Epoch 47/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5673 - val_loss: 0.5646\n",
      "Epoch 48/50\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 0.5669 - val_loss: 0.5642\n",
      "Epoch 49/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5665 - val_loss: 0.5641\n",
      "Epoch 50/50\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.5662 - val_loss: 0.5636\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Train the Autoencoder\n",
    "X_train_normal = X_train[y_train == 0]\n",
    "\n",
    "history = autoencoder.fit(X_train_normal, X_train_normal,\n",
    "                          epochs=50,\n",
    "                          batch_size=32,\n",
    "                          validation_data=(X_test[y_test == 0], X_test[y_test == 0]),\n",
    "                          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyDVAMBmpUY6",
    "outputId": "2db165cb-4bc8-44eb-b846-3fde87104134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Set a Threshold for Reconstruction Error\n",
    "reconstructions = autoencoder.predict(X_train_normal)\n",
    "reconstruction_errors = np.mean(np.square(reconstructions - X_train_normal), axis=1)\n",
    "threshold = np.percentile(reconstruction_errors, 63)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FL4EWOdDpVzz",
    "outputId": "8a2db83e-218e-4ea3-d123-4656b0bd1d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Detect Anomalies on Test Data\n",
    "test_reconstructions = autoencoder.predict(X_test)\n",
    "test_reconstruction_errors = np.mean(np.square(test_reconstructions - X_test), axis=1)\n",
    "y_pred = (test_reconstruction_errors > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDLkwhFSpXF1",
    "outputId": "fe88036b-698a-4b99-f6c9-53989eda8f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5953237410071942\n",
      "Confusion Matrix:\n",
      " [[627 390]\n",
      " [ 60  35]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.62      0.74      1017\n",
      "           1       0.08      0.37      0.13        95\n",
      "\n",
      "    accuracy                           0.60      1112\n",
      "   macro avg       0.50      0.49      0.44      1112\n",
      "weighted avg       0.84      0.60      0.68      1112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Evaluate the Model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "oxXS5nA8qMG_"
   },
   "outputs": [],
   "source": [
    "results_dict = {\"Model\":\"AutoEncoder\",\n",
    "                \"Dataset\":\"Filtered\",\n",
    "                \"Accuracy\":accuracy_score(y_test, y_pred),\n",
    "                \"Recall\":recall_score(y_test, y_pred)}\n",
    "\n",
    "results_list.append(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Nd2E9JlIMbKK"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv(\"results_to_add.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJZV9qU-MkHi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
